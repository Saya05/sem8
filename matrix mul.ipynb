{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNV76XFcjOlcKualWjfUMo/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ql1djDq0THpZ","executionInfo":{"status":"ok","timestamp":1684571783439,"user_tz":-330,"elapsed":7483,"user":{"displayName":"Sayali Nagarkar","userId":"05776882071330272035"}},"outputId":"b8699a72-1677-435e-f895-7becd44e0495"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/afnan47/cuda.git\n","  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-us5cp1gt\n","  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-us5cp1gt\n","  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=cf42e146523290b269c2ad6a92f40b97b3e9f310d0062550bed3ac12fe14c573\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vk4gakgd/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"]}],"source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n","%load_ext nvcc_plugin"]},{"cell_type":"code","source":["%%cu\n","#include <iostream>\n","using namespace std;\n","\n","\n","// CUDA code to multiply matrices\n","__global__ void multiply(int* A, int* B, int* C, int size) {\n","    // Uses thread idices and block indices to compute each element\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < size && col < size) {\n","        int sum = 0;\n","        for (int i = 0; i < size; i++) {\n","            sum += A[row * size + i] * B[i * size + col];\n","        }\n","        C[row * size + col] = sum;\n","    }\n","}\n","\n","\n","void initialize(int* matrix, int size) {\n","    for (int i = 0; i < size * size; i++) {\n","        matrix[i] = rand() % 10;\n","    }\n","}\n","\n","\n","void print(int* matrix, int size) {\n","    for (int row = 0; row < size; row++) {\n","        for (int col = 0; col < size; col++) {\n","            cout << matrix[row * size + col] << \" \";\n","        }\n","        cout << '\\n';\n","    }\n","    cout << '\\n';\n","}\n","\n","\n","int main() {\n","    int* A, * B, * C;\n","\n","    int N = 4;\n","    int blockSize =  16;\n","\n","    int matrixSize = N * N;\n","    size_t matrixBytes = matrixSize * sizeof(int);\n","\n","    A = new int[matrixSize];\n","    B = new int[matrixSize];\n","    C = new int[matrixSize];\n","\n","    initialize(A, N);\n","    initialize(B, N);\n","    cout << \"Matrix A: \\n\";\n","    print(A, N);\n","\n","    cout << \"Matrix B: \\n\";\n","    print(B, N);\n","\n","    \n","    int* X, * Y, * Z;\n","    // Allocate space\n","    cudaMalloc(&X, matrixBytes);\n","    cudaMalloc(&Y, matrixBytes);\n","    cudaMalloc(&Z, matrixBytes);\n","\n","    // Copy values from A to X\n","    cudaMemcpy(X, A, matrixBytes, cudaMemcpyHostToDevice);\n","    \n","    // Copy values from A to X and B to Y\n","    cudaMemcpy(Y, B, matrixBytes, cudaMemcpyHostToDevice);\n","\n","    // Threads per CTA dimension\n","    int THREADS = 2;\n","\n","    // Blocks per grid dimension (assumes THREADS divides N evenly)\n","    int BLOCKS = N / THREADS;\n","\n","    // Use dim3 structs for block  and grid dimensions\n","    dim3 threads(THREADS, THREADS);\n","    dim3 blocks(BLOCKS, BLOCKS);\n","\n","    // Launch kernel\n","    multiply<<<blocks, threads>>>(X, Y, Z, N);\n","\n","    cudaMemcpy(C, Z, matrixBytes, cudaMemcpyDeviceToHost);\n","    cout << \"Multiplication of matrix A and B: \\n\";\n","    print(C, N);\n","\n","    delete[] A;\n","    delete[] B;\n","    delete[] C;\n","\n","    cudaFree(X);\n","    cudaFree(Y);\n","    cudaFree(Z);\n","\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIAWvaKlTeB0","executionInfo":{"status":"ok","timestamp":1684572071079,"user_tz":-330,"elapsed":1998,"user":{"displayName":"Sayali Nagarkar","userId":"05776882071330272035"}},"outputId":"712e4f5a-c68b-490e-dd09-d9e27d0520b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix A: \n","3 6 7 5 \n","3 5 6 2 \n","9 1 2 7 \n","0 9 3 6 \n","\n","Matrix B: \n","0 6 2 6 \n","1 8 7 9 \n","2 0 2 3 \n","7 5 9 2 \n","\n","Multiplication of matrix A and B: \n","55 91 107 103 \n","31 68 71 85 \n","54 97 92 83 \n","57 102 123 102 \n","\n","\n"]}]}]}